The procedure for recasting existing \monoX analyses to obtain SiM constraints follows a simple cut-and-count methodology. Firstly, signal events are simulated (described below in section \ref{signal_generation}) with object $p_{\mathrm{T}}$ smearing applied to approximate the detection efficiency of the ATLAS detector, $\epsilon$. The event selection criteria of the \monoX analysis of interest is then applied to the simulated signal samples. Events surviving the selection criteria are counted to determine the likelihood of a dark matter event being observed (referred to as the acceptance, $\mathcal{A}$), which is then used in combination with channel-specific model-independent limits on new physics events to limit the parameter phase space of a given model.
For a comprehensive description of the recasting procedure, see appendix \ref{Appendix_limitsetting}.
%\bigskip

In this paper, \monojet constraints are derived from a search for new phenomena conducted by the ATLAS Collaboration using $pp$ collisions at $\sqrt{s}=$ 8 TeV as described in ref. \cite{Aad:2015zva}. Similarly, the leptonic \monoZ and hadronic \monoWZ constraints are derived from ATLAS dark matter searches originally optimised for the D1, D5 and D9 effective operators \cite{Aad:2014monoZlep, ATLASmonoWZ}. These analyses are described in further detail in sections \ref{monojet_constraints}, \ref{monoZ_constraints} and \ref{monoWZ_constraints} respectively.

%\comm{We should put references to all the papers here! - Amelia}

\subsection{Signal Simulation}
\label{signal_generation}
Monte Carlo simulated event samples are used to model the expected signal for each channel and for each simplified model. Leading order matrix elements for the process $pp \rightarrow \mathrm{X} + \chi\bar{\chi}$ (where $X$ is specifically one or two jets\footnote{Jets are seeded by any parton excluding the (anti-)top quark.}, a $Z(\rightarrow \ell^+ \ell^-)$ boson or a $W/Z(\rightarrow$ $jj$) boson) are first simulated using \MG$\_${\footnotesize A}MC$@$NLO v2.2.2 \cite{MG_aMCNLO2014} with the MSTW2008lo68cl PDF \cite{MSTW}. During this stage, the renormalisation and factorisation scales are set to the default sum of $\sqrt{m^{2} + p_{T}^{2}}$ for all particles in the final state. Showering and hadronisation are then performed by \PYTHIA  8.201 \cite{} with the appropriate PDF and using the ATLAS UE Tune AU2-MSTW2008LO~\cite{AUtune}. Reconstruction of small-radius jets (from hereon referred to just as `jets') for the \monojet channel is performed by FastJet \cite{} using the anti-$k_{\mathrm{T}}$ algorithm with radius parameter $R$ = 0.4. Similarly, reconstruction of large-radius jets for the \monoWZ channel is performed using the Cambridge-Aachen algorithm with $R$ = 1.2. The latter channel also includes a mass-drop filtering procedure with $\mu$ = 0.67 and $\sqrt{y}$\footnote{$\sqrt{y} = \mathrm{min}(p_{\mathrm{T}_{j1}},p_{\mathrm{T}_{j2}})\Delta R / m_{jet}$ is the momentum balance of the two leading subjets.} = 0.4 (see ref.~\cite{} for further details), which favours large-$R$ jets with two balanced subjets, consistent with the decay of an EW boson to a (potentially-boosted) dijet pair. Lastly, the detector response is approximated by applying a Gaussian smearing factor to the $p_{\mathrm{T}}$ of all leptons and jets.

\subsubsection{Parton Matching Scheme}
\label{matching_procedure}
%\comm{Make explicit the choice of $(0+1+2)j$ vs $(1+2)j$ here.}
%\comm{Also refer to the Papucci paper, and why we don't split the sample. Do we think this is still necessary?}
In the ATLAS \monojet analysis, matching of partons generated in \MG$\mbox{\tiny }$ to jets generated in \PYTHIA is performed using the MLM scheme, with two matching scales, or values of `QCUT', per mass/coupling point. The QCUT values span a broad kinematic range in combination with a cut placed on the leading jet $p_{\mathrm{T}}$ per event to avoid double-counting. This treatment aims to mitigate the impact of the matching scale on the shape of the $p_{\mathrm{T}}$ and $\met$ distributions; that is, to reduce the uncertainty in those areas of phase space where the mediator mass is significantly larger or smaller that the QCUT value. For the analysis of SiMs, we use instead a single matching scale of 80 GeV. Though not ideal, this approach suitably reproduces the results of the ATLAS \monojet analysis for the masses of interest (see Sec. \ref{monojet_validation}). Importantly, it also reduces the complexity and computational expense involved in estimating limits for the \monojet channel.

\bigskip
We now move to a discussion of each of the \monoX channels separately.

\subsection{Mono-jet Constraints}
\label{monojet_constraints}
The ATLAS \monojet + $\met$ analysis \cite{Aad:2015zva} was originally designed to set limits on three new physics scenarios,
%\st{: the production of light grativinos in association with gluinos or scalar quarks in a gauge-mediated supersymmetric model, the production of graviton modes in the Arkani-Hamed, Dimopoulos, and Dvali model for large extra spatial dimensions, and}
the most relevant of which is the production of WIMP DM within the context of seven \comm{(?)} effective operators. The analysis also includes a brief study of a $Z'$ DM model which is analogous to our $sV$ model.
%\bigskip

Signal selection is carried out based on at least one hard jet recoiling against missing energy. To ensure that the correct back-to-back jet + $\met$ topology is selected events are required to have a leading jet, $j_{1}$, with $p_{T} >$ 120 GeV and $|\eta| <$ 2.0 satisfying $p_{T}^{j_{1}}/\met >$ 0.5. Surviving events must then satisfy $|\Delta\phi(j,\metvec)|>1.0$, where $j$ is any jet with $p_{T} >$ 30 GeV and $|\eta| <$ 4.5. This criterion reduces the multijet background contribution where the large $\met$ originates mainly from jet energy mismeasurement. Note that there is no upper limit placed on the number of jets per event. The contribution from the dominant background processes, $W/Z+$jets
%(\footnote{Do I want to be more specific here? Eg. $W (\rightarrow \ell \nu)+$jets, $Z(\rightarrow \nu\bar{\nu})+$jets, $Z/\gamma^{*}(\rightarrow \ell^{+}\ell^{-})+$jets?})
, is managed with a veto on events containing muons or electrons with $p_{T}>$ 7 GeV. A further veto is placed on events containing isolated tracks\footnote{A track is considered isolated when no additional track with $p_{T} >$ 3 GeV lies within a cone of radius 0.4 around it.} with $p_{T}>$ 10 GeV and $|\eta| <$ 2.5, to reduce the contribution from non-identified leptons ($e$, $\mu$ or $\tau$) in the final state. Lastly, nine separate signal regions are defined with increasing lower thresholds on $\met$, which range from 150 GeV to 700 GeV as shown in table \ref{monojet_SRs}.
%\st{initially, events are required to have $\met>$ 150 GeV and at least one jet with $p_{T} >$ 30 GeV and $|\eta| <$ 4.5} (\comm{My logic here is that these cuts are for trigger, or pre-selection - they are overwritten by later cuts, right? So I think not worth including.}). we require $|\Delta\phi(\mathrm{j},\metvec)|>1.0$, where j is any jet with $p_{T} >$ 30 GeV and $|\eta| <$ 4.5.  have a leading jet (\comm{Is this the dominant background? If so, include `dominant', if not, this cut is maybe better understood as implementing back-to-backness. Is there an upper limit on $N_{jets}$?}). \comm{Note to self: include lepton veto criteria here.}
%\bigskip

The ATLAS \monojet analysis revealed no significant deviation of observed events from the expected SM backgrounds in the Run 1 8 TeV dataset. Subsequently, model-independent limits on new physics signatures were provided in terms of the visible cross-section, $\sigma\times\mathcal{A}\times\epsilon$; these are listed in table \ref{monojet_SRs}.

\begin{table}[!htbp]
\centering
\begin{tabular}{c|c|c}
 \hline
 \hline
 Signal Region & $\met$ threshold [GeV] & $\sigma \times \mathcal{A} \times \epsilon$ [fb] \\ %$N_{obs}$ & $N_{exp}$ \\%& $N_{obs}/\mathcal{L}$ & $N_{exp}/\mathcal{L}$ \\
 \hline
 SR1 & 150 & 726 (935) \\ %14737.8 & 18980.5 \\%726 & 935 \\
 SR2 & 200 & 194 (271) \\ %3938.2 & 5501.3 \\%194 & 271 \\
 SR3 & 250 & 90 (106) \\ %1827 & 2151.8 \\%90 & 106 \\
 SR4 & 300 & 45 (51) \\ %913.5 & 1035.3 \\%45 & 51 \\
 SR5 & 350 & 21 (29) \\ %426.3 & 588.7 \\%21 & 29 \\
 SR6 & 400 & 12 (17) \\ %243.6 & 345.1 \\%12 & 17 \\
 SR7 & 500 & 7.2 (7.2) \\ %146.16 & 146.16 \\%7.2 & 7.2 \\
 SR8 & 600 & 3.8 (3.2) \\ %77.14 & 73.08 \\%3.8 & 3.6 \\
 SR9 & 700 & 3.4 (1.8) \\ %69.02 & 36.54 \\%3.4 & 1.8 \\
 \hline
 \hline
\end{tabular}
\caption{The ATLAS \monojet $\met$ signal regions and corresponding observed (expected) model-independent upper limits on $\sigma \times \mathcal{A} \times \epsilon$ at 95\% confidence level. Adapted from Ref. \cite{Aad:2015zva}.
%The ATLAS model-independent upper limits on the number of observed (expected) signal events, $N_{obs}$ ($N_{exp}$), at 95\% confidence level for the \monojet channel signal regions.
%\comm{Since this table is adapted from the \monojet paper, I think we should reproduce exactly what they show, ie the limit on $\sigma \times \mathcal{A} \times \epsilon$. Part of the reason is that if you multiply their values by the lumi, this is ignoring the uncertainty on that lumi that they've already included. More importantly, I don't think there is any advantage in showing the limits on $N$, since to obtain limits on $\sigma$ we divide immediately by $\mathcal{L}$ again anyway, plus the audience may be more familiar with the limit on $\sigma \times \mathcal{A} \times \epsilon$.}
}
\label{monojet_SRs}
\end{table}

The signal simulation procedure outlined in sec. \ref{signal_generation} and implementation of the selection criteria discussed above were validated for the \monojet channel via reproduction of ATLAS limits on the suppression scale, $\Mstar \equiv \Mmed / \sqrtgqgX$, for the $Z'$ model. The details of this process are contained in appendix \ref{monojet_validation}. Importantly, we observe agreement within $\sim$12\% for all samples.

%\st{Note that we only calculate limits on M$_{*}$ for this aspect of the analysis. Although it is customary to present constraints on dark matter models in the form of limits on M$_{*}$, we shall hereafter present constraints in the form of limits on the cross-section. This is done to better facilitate the comparison of collider and direct detection results, where $\sigma(pp \rightarrow X + \chi\bar{\chi})$ and $\sigma(N\chi \rightarrow N\chi)$ are related by a Fierz transformation in the simplified model framework} \cite{PJFox, NBellDent}.

%\draft{While the signal samples used by the ATLAS group (and for validation) correspond to the processes $pp \rightarrow j\chi\bar{\chi}$ and $pp \rightarrow jj\chi\bar{\chi}$ where $j$ is a final state jet, \monojet constraints on the simplified models studied in this paper were set using signal samples with zero, one and two jets in the final state.} \comm{This deviation from the ATLAS analysis is motivated by the observation that the limits on $\Mstar$ are improved with the addition of the process $pp \rightarrow \chi\bar{\chi}$.}
%However, while the ATLAS MC samples are generated for only two matching scale values (80 GeV and 300 GeV), we use a sliding value of $\mX/4$. \comm{This ensures that all jet-related kinematic distributions are smoothly connected across all dark matter masspoints.}

\subsection{Mono-$Z$ Constraints}
\label{monoZ_constraints}
The ATLAS mono-$Z(\rightarrow \ell^+ \ell^-)$ + $\met$ analysis \cite{Aad:2014monoZlep} was principally designed to constrain a set of EFT models of DM. As a secondary focus, it also includes a short study of a $t$-channel simplified model similar to our $tS$ model.
%\textcolor{blue}{This model is used to validate our results in this channel; see the details in sec.~\ref{monoZ_validation}.} \comm{Can this go at the end of this subsection?}

The selection criteria for this analysis are summarised as follows (see the paper for a full description). Electrons (muons) are required to have a $p_{\mathrm{T}}$ greater than 20 GeV, and $|\eta|$ less than 2.47 (2.5). Two opposite-sign, same-flavour leptons are selected, and required to have invariant mass and pseudorapidity such that $m_{\ell \ell} \in [76, 106]$ GeV and $|\eta^{\ell \ell}| < 2.5$. The reconstructed $Z$ boson should be approximately back-to-back and balanced against the $\met$, ensured with the selections $\Delta \phi (\metvec, p_{\mathrm{T}}^{\ell \ell}) > 2.5$ and $| p_{\mathrm{T}}^{\ell \ell} - \met | \, /  \, p_{\mathrm{T}}^{\ell \ell} < 0.5$. Events containing a jet with $p_{\mathrm{T}}>$ 25 GeV and $|\eta|< $ 2.5 are vetoed. Events are also vetoed if they contain a third lepton with $p_{\mathrm{T}}>$ 7 GeV. The signal regions are defined by increasing lower $\met$ thresholds: $\met >$ 150, 250, 350, 450 GeV.

% Note: I haven't included any info on the overlap removal here.

%The dominant background in this analysis is the irreducible $ZZ \rightarrow \ell^+ \ell^- \bar{\nu} \nu$ process, which has a softer $\met$ distribution that the DM signal. The background is estimated with MC simulation, and has a systematic uncertainty in the range 36-46$\%$ across the four signal regions.

A cut-and-count strategy is used to estimate the total observed yields and expected SM backgrounds in each signal region. The limits on $\sigma\times\mathcal{A}\times\epsilon$ are not publicly available, so we take the numbers of expected and observed events, along with the associated uncertainties, and convert these into model-dependent upper limits with a single implementation of the HistFitter package \cite{} using a frequentist calculator and a one-sided profile likelihood test statistic (the LHC default). The results of this process are displayed in table~\ref{tab:Nlim_monoZ}.


The statistical, systematic, and luminosity uncertainties are added in quadrature to give the total background estimate and uncertainty. We convert these into model-independent upper limits on the expected (observed) number of new physics events, $N^{\mathrm{exp}}$ ($N^{\mathrm{obs}}$), with a simple implementation of HistFitter that uses a frequentist calculator and a one-sided profile likelihood test statistic (the LHC default). The results of this process are presented in Table \ref{tab:Nlim_monoZ}. Note that we use signal regions 1 and 2 only, as our simplified HistFitter approach is inadequate to handle the very low statistics of signal regions 3 and 4. These upper limits are also used for the validation of the \monoZ signal generation and selection procedures (see app.~\ref{monoZ_validation}).

\begin{table}
\begin{center}
\begin{tabular}{ c  c  c }
\hline
\hline
& SR1 & SR2 \T \\
& ($E_{\mathrm{T}}^{\mathrm{miss}} > $ 150 GeV) & ($E_{\mathrm{T}}^{\mathrm{miss}} > $ 250 GeV) \B \\
\hline
$N^{\mathrm{exp}}$ & 34.7 & 6.8 \T \\
$N^{\mathrm{obs}}$ & 32.2 & 5.9 \B \\
\hline
\hline
\end{tabular}
\end{center}
\label{tab:Nlim_monoZ}
\caption{The expected and observed upper limits on the number of new physics events in the ATLAS \monoZ analysis, calculated with HistFitter using the results of \cite{Aad:2014monoZlep}.}
\end{table}

\subsection{Mono-$W/Z$ Constraints}
\label{monoWZ_constraints}

The ATLAS \monoWZ + $\met$ search \cite{} was originally aimed at constraining the spin-independent effective operators C1, D1, and D5, and the spin-dependent D9. The search was originally designed to exploit the constructive interference of $W$ boson emission from opposite-sign up-type and down-type quarks, leading to DM production wherein the mono-$W$ channel is dominant. Recent studies \cite{} have revealed this scenario to violate unitarity and so we ignore it in this analysis.
%The analysis focusing on fully-hadronic decays of the bosons in the \monoWZ channel performed by ATLAS on the 8 TeV dataset was considered especially interesting, since constructive interference in the mono-$W(\rightarrow \ell \nu)$ channel was assumed to be possible for the vector EFT operator, leading to stronger limits than those from the \monojet searches in this case. More recently however, studies have revealed that such a scenario would violate unitarity and this interpretation is not emphasised in this work due to these concerns.
%
%Nevertheless, this channel is an interesting addition, since it exploits the large branching fraction of hadronic boson decays. Also, the experimental techniques applied are significantly different; the selection is based on large-$R$ jets that are consistent with having come from an electroweak boson. In addition, large $\met$ is required, as for all \monoX searches.

The \monoWZ event selection is carried out as follows. Large-radius jets are selected using a mass-drop filtering procedure (see sec.~\ref{signal_generation}) to suppress non-$W/Z$ processes. Events are required to contain at least one large-$R$ jet with $p_{\mathrm{T}} >$ 250 GeV, $|\eta| <$ 1.2 and a mass, $m_{\mathrm{jet}}$, within a 30-40 GeV window of the $W/Z$ mass (i.e. $m_{\mathrm{jet}} \in [50, 120]$ GeV). In order to reduce the $t \bar{t}$ and multijet backgrounds, a veto removes events containing a small-$R$ jet with $\Delta\phi(\mathrm{jet},\met)< 0.4$, or containing more than one small-$R$ jet with $p_{\mathrm{T}} >$ 40 GeV, $|\eta| <$ 4.5, and $\Delta R$(small-$R$ jet, large-$R$ jet)$>0.9$. Electrons, muons and photons are vetoed if their $p_{\mathrm{T}}$ is larger than 10 GeV and they lie within $|\eta| <$ 2.47 (electrons), 2.5 (muons), 2.37 (photons). Two signal regions are defined with $\met > 350$ GeV and $\met > 500$ GeV. Note that, in the recasting procedure, we consider only the second signal region (see Sec. \ref{} for further details). (\comm{should have a statement explaining this choice}).

%The main background is due to $Z \rightarrow \bar{\nu} \nu$ events with additional jets from initial state radiation. Further important backgrounds from $W/Z$+jets events, in which the boson decays leptonically, enter the selection if the lepton(s) is missed due to being out of the acceptance range or failing ID requirements, or in the case that it is a hadronically-decaying $\tau$ lepton. All these backgrounds are estimated by the original analysis in dedicated control regions.

The ATLAS analysis used a shape-fit of the mass distribution of the large-$R$ jet to estimate the background yields in the two signal regions, along with the associated statistical and systematic uncertainties. As in the \monoZ case, we convert these values into upper limits on the expected and observed number of new physics events using the HistFitter package. For the $\met > 500$ GeV signal region, we obtain $N^{exp} = 27.2$ and $N^{obs} = 27.4$.
%, we simply regard the number of events in the signal region, since the data points of the $m_{\rm jet}$ distribution were not published. \comm{check!!!} From the published number of expected and observed events in the signal region and their uncertainties, we \comm{use HistFitter to} calculate the upper limit on the number of new physics events as described above for the \monoZ channel (see eq.~\ref{sigma_nom}). We obtain the following numbers: $N_{exp} = 27.2$, $N_{obs} = 27.4$.
